## <NAME>
## 
## DESCRIPTION
## 
## Rules
## -----
##

configfile: "config/config.yml"

SAMPLES = config["samples"]
DIRECTIONS = {'R1', "R2"}
SEQNAMES = SAMPLES['reference'] + SAMPLES['query']

SUMMARIES = ["multiqc-fastqc", "multiqc-assembly"]

rule all:
  input:
    "data/data",
    # the reference
    reference_assembly=expand("results/data/assembly/{seqname}-spades", 
        seqname = SAMPLES['reference']),
    summary=expand("results/summary/{summary}", summary=SUMMARIES),
    mapping=expand("results/data/mapping/{seqname}-{query}.pe.sam",
        query=SAMPLES["query"], seqname=SAMPLES["reference"])


checkpoint download_data:
  output: directory("data/data")
  shell:
    """
    mkdir -p {output}
    cd data
    wget https://osf.io/2jc4a/download -O download.tar.gz
    tar -xzf download.tar.gz
    """


def get_sequence_files(wildcards):
  """Get the sequence names of the downloaded data
  """
  checkpoint_output = checkpoints.download_data.get(**wildcards).output[0]
  files = [f for f in os.listdir(checkpoint_output) if not f.startswith('.')]
  out = [f"{checkpoint_output}/{d}" for d in files if d.endswith("fastq.gz") and d.startswith(wildcards.seqname)]
  return out


rule move:
  input:
    get_sequence_files
  output:
    "results/data/raw/{seqname}.fastq.gz"
  shell:
    """
    cp {input} {output}
    """

## fastqc:
##    Analyse quality of FASTQ sequences using fastqc.
##
rule fastqc:
  conda: "envs/qc.yml"
  input: 
    "results/data/{step}/{seqname}_{direction}.fastq.gz" 
  output:
    directory("results/quality-control/data/fastqc/{step}/{seqname}_{direction}")
  shell: "mkdir -p {output}; fastqc {input} -o {output}"

## quality_report_fastqc:
##    Compile seperate quality metrics per tool into a single report.
##
rule quality_report_fastqc:
  conda: "envs/qc.yml"
  input:
    expand("results/quality-control/data/fastqc/{step}/{seqname}_{direction}",
        step=["raw", "trimmed"], seqname=SEQNAMES, direction=DIRECTIONS)
  output: directory("results/summary/multiqc-fastqc")
  shell: "mkdir {output}; multiqc -d {input} -o {output}"

## trimming:
##    Quality trimming of fastq files.
##
rule trimming:
  conda: "envs/qc.yml"
  input:
    P1="results/data/raw/{seqname}_R1.fastq.gz",
    P2="results/data/raw/{seqname}_R2.fastq.gz"
  output:
    P1="results/data/trimmed/{seqname}_R1.fastq.gz",
    P2="results/data/trimmed/{seqname}_R2.fastq.gz",
    html_report="results/quality-control/data/trimmed/{seqname}.html",
    json_report="results/quality-control/data/trimmed/{seqname}.json"
  shell:
    """
    fastp --detect_adapter_for_pe \
      --overrepresentation_analysis \
      --correction \
      --cut_right \
      --thread 2 \
      --html {output.html_report} \
      --json {output.json_report} \
      -i {input.P1}  -I {input.P2} \
      -o {output.P1} -O {output.P2}
    """

## assembly:
##    Assemble sequences into contigs.
##
checkpoint assembly:
  conda: "envs/assembly.yml"
  input:
    P1="results/data/trimmed/{seqname}_R1.fastq.gz",
    P2="results/data/trimmed/{seqname}_R2.fastq.gz"
  output:
    directory("results/data/assembly/{seqname}-spades")
  shell:
    """
    mkdir -p {output}
    spades.py -o {output} -1 {input.P1} -2 {input.P2} --isolate
    """


def get_assembled_fasta(wildcards):
  """Get the sequence names of the downloaded data
  """
  checkpoint_output = checkpoints.assembly.get(**wildcards).output[0]
  return f"{checkpoint_output}/contigs.fasta"


rule assembly_qc:
  conda: "envs/assembly.yml"
  input: get_assembled_fasta
  output: directory("results/quality-control/assembly/{seqname}-stats")
  message: "Running Quast on {input}"
  shell:
    """
    mkdir {output}
    quast {input} -o  {output}
    """

rule quality_report_assembly:
  conda: "envs/qc.yml"
  input: expand("results/quality-control/assembly/{seqname}-stats", seqname=SAMPLES["reference"])
  output: directory("results/summary/multiqc-assembly")
  shell: "mkdir {output}; multiqc {input} -o {output}"


rule mapping_index:
  conda: "envs/mapping.yml"
  input: get_assembled_fasta
  output: touch("results/data/mapping/{seqname}.indexed")
  shell: "bwa index {input}"
  
rule mapping_mem:
  conda: "envs/mapping.yml"
  input:
    p1="results/data/trimmed/{query}_R1.fastq.gz",
    p2="results/data/trimmed/{query}_R2.fastq.gz",
    seqname=get_assembled_fasta,
    index="results/data/mapping/{seqname}.indexed"
  output: temp("results/data/mapping/{seqname}-{query}.pe.sam")
  shell: "bwa mem {input.seqname} {input.p1} {input.p2} > {output}"

rule fix_mates:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{seqname}-{query}.pe.sam"
  output: "results/data/mapping/{seqname}-{query}.pe.fixmate.bam"
  shell:
    """
    samtools sort -n -O  sam {input} | samtools fixmate -m -O bam -  {output}
    """
  

rule sort_coordinate:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{seqname}-{query}.pe.sorted.bam"
  output: "results/data/mapping/{seqname}-{query}.pe.sorted.bam"
  shell:
    """
    samtools sort -r -S {input}  {output}
    """

rule sort_group:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{seqname}-{query}.pe.sorted.deduped.bam"
  output: "results/data/mapping/{seqname}-{query}.pe.grouped.bam"
  shell:
    """
    samtools sort -N -O bam {input} -o {output}
    """

rule dedupe:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{seqname}-{query}.pe.fixmate.bam"
  output: "results/data/mapping/{seqname}-{query}.pe.sorted.deduped.bam"
  shell:
    """
   samtools sort {input} |  samtools markdup  -S -  {output}
    """

rule map_summary:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{mapping}.pe.grouped.bam"
  output: "results/summary/{mapping}-samtools.txt"
  shell: "samtools flagstats {input} > {output}; cat {output}"

rule coverage_stats:
  conda: "envs/mapping.yml"
  input: "results/data/mapping/{seqname}-{query}.pe.sorted.deduped.bam"
  output: "results/statistics/assembly/{seqname}-{query}.depth.txt.gz"
  shell:
    """
    samtools depth {input} | gzip > {output}
    """

rule coverage_stats_filter:
  input: "results/statistics/assembly/{seqname}-{query}.depth.txt.gz"
  output: "results/statistics/assembly/{seqname}-{query}_node-{id}_depth.txt.gz"
  shell:
    """
    zcat {input} | grep "^NODE_{wildcards.id}" > {output}
    """

rule coverage_stats_contig:
  conda: "envs/r-analysis.yml"
  input: "results/statistics/assembly/{seqname}-{query}_node-{id}_depth.txt.gz"
  output: "results/statistics/assembly/{seqname}-{query}_node-{id}_depth.pdf"
  shell:
    """
    Rscript workflow/scripts/assembly-depth.R -i {input} -o {output}
    """

## help:
##    Show the help.
##
rule help:
  input: "workflow/Snakefile"
  shell: "sed -n 's/^##//p' {input}"


## clean:
##    Clean all outputs from the results folder.
##
rule clean:
  shell: "rm -rf results/*"


## build_overview:
##    Print the directed acyclic graph.
##
rule build_overview:
  conda: "envs/utils.yml"
  input:
    "results/data/mapping/anc-evol2.pe.sam"
  output:
    "results/method.{fileformat}"
  shell:
    """
    snakemake -c 1 {input} --forceall --dag | dot -T{wildcards.fileformat} > {output}
    """


rule install_easy_graph:
  conda:
    "envs/utils.yml"
  output:
    touch("results/checkpoints/install_easy_graph")
  shell:
    """
    echo "Installing easy graph"
    cpan -i App::cpanminus
    cpanm Graph::Easy
    """

    
## build_overview_ascii:
##    Prints the graph in ascii format.
rule build_ascii_graph:
  conda:
    "envs/utils.yml"
  input:
    "results/checkpoints/install_easy_graph"
  output:
    "results/method-simple.ascii"
  shell:
    """
    snakemake -c 1 --forceall --dag > out
    graph-easy --from=dot --as_ascii out >  {output}
    rm out
    """
